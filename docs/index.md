---
title: "Overview"
nav_order: 1
---

# HSR Multimodal Interaction Stack

This documentation describes the multimodal speech, tone, and LLM-based interaction system developed for the Toyota Human Support Robot (HSR).

The system integrates:
- Whisper ASR  
- Voice Activity Detection (VAD)  
- CRNN-based tone/emotion analysis  
- GPT-based dialogue manager  
- ROS 2 gesture and behavior controllers  

## Contents

- [System Architecture](architecture.md)
- [Installation & Setup](setup.md)
- [Usage Guide](usage.md)


